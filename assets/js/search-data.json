{
  
    
        "post0": {
            "title": "ResNet from scatch in PyTorch",
            "content": "Imports and Notebook setup . from tqdm.notebook import tqdm . import os if os.environ.get(&#39;KAGGLE_KERNEL_RUN_TYPE&#39;, &#39;Localhost&#39;) != &#39;Losthost&#39;: # library with nice formating os.system(&quot;pip install rich&quot;) . import rich from collections import OrderedDict . import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim . from torch.utils.data import dataset, dataloader, random_split from torchvision.datasets import CIFAR10 from torchvision.transforms import ToTensor, Lambda, Compose . dataset = CIFAR10(root=&quot;/kaggle/working/data/&quot;, download=True, train=True, transform=ToTensor()) test_dataset = CIFAR10(root=&quot;/kaggle/working/data/&quot;, download=True, train=False, transform=ToTensor()) # create train, valid datasets valid_size = int(dataset.data.shape[0]*0.1) train_size = dataset.data.shape[0] - valid_size train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size]) . Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /kaggle/working/data/cifar-10-python.tar.gz Extracting /kaggle/working/data/cifar-10-python.tar.gz to /kaggle/working/data/ Files already downloaded and verified . config = OrderedDict() config[&#39;batch_size&#39;] = 128 . train_dataloader = dataloader.DataLoader(train_dataset, batch_size=config[&#39;batch_size&#39;]) valid_dataloader = dataloader.DataLoader(valid_dataset, batch_size=config[&#39;batch_size&#39;]) test_dataloader = dataloader.DataLoader(test_dataset, batch_size=config[&#39;batch_size&#39;]) . for x, y in train_dataloader: rich.print(x.max(), x.min()) rich.print(y) break . tensor(1.) tensor(0.) . tensor([3, 0, 8, 3, 1, 4, 0, 6, 5, 7, 9, 5, 1, 4, 2, 8, 4, 2, 9, 7, 4, 8, 2, 9, 3, 6, 2, 3, 3, 2, 5, 3, 7, 1, 9, 7, 2, 8, 2, 1, 0, 8, 9, 0, 6, 2, 3, 0, 8, 4, 9, 6, 3, 3, 6, 5, 0, 6, 2, 0, 9, 5, 0, 4, 5, 2, 5, 9, 6, 3, 5, 6, 4, 5, 5, 3, 7, 5, 0, 7, 5, 2, 1, 9, 2, 8, 2, 6, 5, 9, 3, 4, 6, 8, 4, 8, 1, 2, 4, 5, 4, 1, 6, 1, 8, 9, 3, 5, 6, 1, 0, 3, 0, 7, 2, 9, 8, 3, 3, 6, 3, 1, 3, 1, 7, 9, 5, 4]) . ResNet Block . class ResNetBlock(nn.Module): def __init__(self, in_channels: int = 32, num_filters: int = 64): super().__init__() self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=num_filters, kernel_size=3, padding=1) self.bn1 = nn.BatchNorm2d(num_filters) self.relu1 = nn.ReLU() self.conv2 = nn.Conv2d(in_channels=num_filters, out_channels=num_filters, kernel_size=3, padding=1) self.bn2 = nn.BatchNorm2d(num_filters) self.relu2 = nn.ReLU() def forward(self, x): z = self.conv1(x) z = self.relu1(z) z = self.bn1(z) z = self.conv2(z) y = self.relu2(z + x) return self.bn2(y) . Check that ResNetBlock has same input and output sizes . rblock = ResNetBlock(in_channels=64) x = torch.randint(0, 100, size=(128, 64, 32, 32), dtype=torch.float32) y = rblock(x) assert x.shape == y.shape . ResNetChangeBlock implements the ResNet with skip connections when the input and output have different shape . class ResNetChangeBlock(nn.Module): def __init__(self, in_channels: int = 32, num_filters: int = 64): super().__init__() self.in_channels = in_channels self.out_channels = num_filters self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=num_filters, stride=2, kernel_size=3, padding=1) self.bn1 = nn.BatchNorm2d(num_filters) self.relu1 = nn.ReLU() self.conv2 = nn.Conv2d(in_channels=num_filters, out_channels=num_filters, kernel_size=3, padding=1) self.bn2 = nn.BatchNorm2d(num_filters) self.relu2 = nn.ReLU() def forward(self, x): n, c, w, h = x.shape z = self.conv1(x) z = self.relu1(z) z = self.bn1(z) z = self.conv2(z) self.zero_identity = nn.Parameter( torch.zeros(n, self.out_channels-self.in_channels, int(w//2), int(h//2)), requires_grad=False ) x_expand = F.pad(x[:, :, :int(w//2), :int(h//2)], pad=( 0, 0, 0, 0, self.out_channels-self.in_channels, 0, 0, 0)) y = self.relu2(z + x_expand) return self.bn2(y) . Check the padding operation works as intended, the pad dimensions are left-to-right last-to-first dimension . x = torch.ones([128, 16, 16, 16]) y = torch.ones([128, 32, 16, 16]) z = F.pad(x, (0, 0, 0, 0, 16, 0, 0, 0)) assert z.shape == y.shape . Check that ResNetChangeBlock has half receptor field . rblock2 = ResNetChangeBlock(in_channels=64, num_filters=128) x = torch.randint(0, 100, size=(128, 64, 32, 32), dtype=torch.float32) y = rblock2(x) assert y.shape == (128, 128, 16, 16) . ResNet with variable 6n+2 number of layers and skip connections 2n skip connections, Similar to CIFAR10 network from the resnet paper. . class ResNet(nn.Module): def __init__(self, n: int = 3, num_classes: int = 10): super().__init__() self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1) self.resblock1_list = nn.ModuleList([ ResNetBlock(in_channels=16, num_filters=16) for _ in range(n) ]) self.resblock2_list = nn.ModuleList([ ResNetChangeBlock(in_channels=16, num_filters=32) ] + [ ResNetBlock(in_channels=32, num_filters=32) for _ in range(n-1) ]) self.resblock3_list = nn.ModuleList([ ResNetChangeBlock(in_channels=32, num_filters=64) ] + [ ResNetBlock(in_channels=64, num_filters=64) for _ in range(n-1) ]) self.linear1 = nn.Linear(in_features=64, out_features=num_classes) def forward(self, x): x = self.conv1(x) for layer1 in self.resblock1_list: x = layer1(x) for layer2 in self.resblock2_list: x = layer2(x) for layer3 in self.resblock3_list: x = layer3(x) x = torch.mean(x, dim=[2, 3]) x = self.linear1(x) return x . Check ResNet has last dimension as num_classes . n = 3 num_classes = 10 batch_size = 128 res_net = ResNet(n=n, num_classes=num_classes) x = torch.randint(0, 100, size=(batch_size, 3, 32, 32), dtype=torch.float32) y = res_net(x) assert y.shape == (batch_size, num_classes) . Define Train and Eval loop . config[&#39;device&#39;] = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot; print(f&quot;device: {config[&#39;device&#39;]}&quot;) # define the network config[&#39;n&#39;] = 3 num_classes = 10 res_net = ResNet(n=config[&#39;n&#39;], num_classes=num_classes) res_net = res_net.to(config[&#39;device&#39;]) loss_fn = nn.CrossEntropyLoss() optimizer = optim.Adam(params=res_net.parameters()) . device: cuda . rich.print(res_net) . ResNet( (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (resblock1_list): ModuleList( (0): ResNetBlock( (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu1): ReLU() (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu2): ReLU() ) (1): ResNetBlock( (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu1): ReLU() (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu2): ReLU() ) (2): ResNetBlock( (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu1): ReLU() (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu2): ReLU() ) ) (resblock2_list): ModuleList( (0): ResNetChangeBlock( (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)) (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu1): ReLU() (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu2): ReLU() ) (1): ResNetBlock( (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu1): ReLU() (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu2): ReLU() ) (2): ResNetBlock( (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu1): ReLU() (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu2): ReLU() ) ) (resblock3_list): ModuleList( (0): ResNetChangeBlock( (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu1): ReLU() (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu2): ReLU() ) (1): ResNetBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu1): ReLU() (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu2): ReLU() ) (2): ResNetBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu1): ReLU() (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu2): ReLU() ) ) (linear1): Linear(in_features=64, out_features=10, bias=True) ) . def train_fn(model: nn.Module, train_dataloader: dataloader.DataLoader, loss_fn, optimizer, epoch: int, device: str): model.train() for batch_index, (X, y) in tqdm(enumerate(train_dataloader), total=len(train_dataloader.dataset.indices)//config[&#39;batch_size&#39;]): X_data, y_data = X.to(device), y.to(device) y_pred = model(X_data) loss = loss_fn(y_pred, y_data) # backprop optimizer.zero_grad() loss.backward() optimizer.step() loss = loss.item() accu = torch.argmax(y_pred, dim=-1) == y_data accu = sum(accu)/len(accu) accu = accu.item() print(&quot;loss=&quot;+str(loss), end=&#39; &#39;) print(&quot;accu=&quot;+str(accu), end=&#39; &#39;) . def test_fn(model: nn.Module, test_dataloader: dataloader.DataLoader, epoch: int, device: str, dataset: str): loss = 0 results = [] model.eval() with torch.no_grad(): for batch_index, (X, y) in tqdm(enumerate(test_dataloader)): X_data, y_data = X.to(device), y.to(device) y_pred = model(X_data) loss += loss_fn(y_pred, y_data).item() results.extend(torch.argmax(y_pred, dim=-1) == y_data) test_accu = sum(results)/len(results) test_accu = test_accu.item() test_loss = loss/len(results) print(dataset + &quot;_loss: &quot; + str(test_loss), end=&#39; &#39;) print(dataset + &quot;_accu: &quot; + str(test_accu), end=&#39; &#39;) return False . Train and Track the Model . config[&#39;num_epochs&#39;] = 25 for epoch in tqdm(range(config[&#39;num_epochs&#39;])): print(&quot;epoch: &quot; + str(epoch), end=&#39; &#39;) train_fn(res_net, train_dataloader, loss_fn, optimizer, epoch, config[&#39;device&#39;]) test_fn(res_net, valid_dataloader, epoch, config[&#39;device&#39;], dataset=&quot;valid&quot;) print() . epoch: 0 loss=1.1741900444030762 accu=0.5 valid_loss: 0.009578690445423126 valid_accu: 0.5667999982833862 epoch: 1 loss=0.9159127473831177 accu=0.6805555820465088 valid_loss: 0.007797019159793854 valid_accu: 0.6571999788284302 epoch: 2 loss=0.7329821586608887 accu=0.7083333134651184 valid_loss: 0.006730758094787598 valid_accu: 0.7023999691009521 epoch: 3 loss=0.5593144297599792 accu=0.7777777910232544 valid_loss: 0.006174366390705109 valid_accu: 0.7310000061988831 epoch: 4 loss=0.500760018825531 accu=0.7777777910232544 valid_loss: 0.006064797937870026 valid_accu: 0.7387999892234802 epoch: 5 loss=0.3587251901626587 accu=0.8611111044883728 valid_loss: 0.00611595823764801 valid_accu: 0.7457999587059021 epoch: 6 loss=0.2707603871822357 accu=0.9166666865348816 valid_loss: 0.006046025335788727 valid_accu: 0.7501999735832214 epoch: 7 loss=0.2549777626991272 accu=0.9027777910232544 valid_loss: 0.00602523101568222 valid_accu: 0.7601999640464783 epoch: 8 loss=0.255811482667923 accu=0.9305555820465088 valid_loss: 0.005957237935066223 valid_accu: 0.7705999612808228 epoch: 9 loss=0.1865358203649521 accu=0.9166666865348816 valid_loss: 0.006287951052188873 valid_accu: 0.7590000033378601 epoch: 10 loss=0.2165629267692566 accu=0.9166666865348816 valid_loss: 0.006590583300590515 valid_accu: 0.7545999884605408 epoch: 11 loss=0.23004494607448578 accu=0.875 valid_loss: 0.007091660153865814 valid_accu: 0.7545999884605408 epoch: 12 loss=0.1190534457564354 accu=0.9583333134651184 valid_loss: 0.007388375395536423 valid_accu: 0.7513999938964844 epoch: 13 loss=0.08894743770360947 accu=0.9722222089767456 valid_loss: 0.007570652145147324 valid_accu: 0.7551999688148499 epoch: 14 loss=0.13272982835769653 accu=0.944444477558136 valid_loss: 0.007181078696250916 valid_accu: 0.7703999876976013 epoch: 15 loss=0.1256604641675949 accu=0.9583333134651184 valid_loss: 0.007560571193695068 valid_accu: 0.76419997215271 epoch: 16 loss=0.04683852195739746 accu=0.9861111044883728 valid_loss: 0.007569316947460175 valid_accu: 0.7784000039100647 epoch: 17 loss=0.0941305011510849 accu=0.944444477558136 valid_loss: 0.0074231725215911865 valid_accu: 0.777999997138977 epoch: 18 loss=0.10060694068670273 accu=0.9722222089767456 valid_loss: 0.00766129287481308 valid_accu: 0.7789999842643738 epoch: 19 loss=0.08288509398698807 accu=0.9583333134651184 valid_loss: 0.00796333611011505 valid_accu: 0.7759999632835388 epoch: 20 loss=0.03118015266954899 accu=1.0 valid_loss: 0.008388083469867707 valid_accu: 0.7735999822616577 epoch: 21 loss=0.0689447894692421 accu=0.9722222089767456 valid_loss: 0.008306311309337617 valid_accu: 0.7755999565124512 epoch: 22 loss=0.10265751928091049 accu=0.944444477558136 valid_loss: 0.00867701324224472 valid_accu: 0.7789999842643738 epoch: 23 loss=0.06691690534353256 accu=0.9583333134651184 valid_loss: 0.008344750368595123 valid_accu: 0.777999997138977 epoch: 24 loss=0.013189314864575863 accu=1.0 valid_loss: 0.008692999589443208 valid_accu: 0.7698000073432922 . Test and Save the network . def predict_fn(model, test_dataloader, device): y_pred_list = [] with torch.no_grad(): for batch_index, (X, y) in enumerate(test_dataloader): X_data, y_data = X.to(device), y.to(device) y_pred = model(X_data) y_pred_list.append(y_pred) return torch.cat(y_pred_list) . test_fn(res_net, test_dataloader, epoch, config[&#39;device&#39;], dataset=&quot;test&quot;) . test_loss: 0.0094959352850914 test_accu: 0.7688999772071838 . False . torch.save(res_net.state_dict(), &quot;resnet_cifar10_n3_network.pth&quot;) . Conclusion and Future work .",
            "url": "https://saratbhargava.github.io/image_recognition/jupyter/2021/10/25/resnet-from-scratch.html",
            "relUrl": "/jupyter/2021/10/25/resnet-from-scratch.html",
            "date": " • Oct 25, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://saratbhargava.github.io/image_recognition/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://saratbhargava.github.io/image_recognition/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}